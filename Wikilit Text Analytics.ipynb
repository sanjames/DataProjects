{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment2 - Text Analytics\n",
    "\n",
    "Purpose: Implement Bag of Words on wikilit webpage and get count the occurrences of all words in the documents. Construct a bag-of-words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Import urllib.request library for opening URLs\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1) Data Preparation & Analysis\n",
    "Get and read the wikilit web page and show the first 2000 characters to make sure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\" dir=\"ltr\" class=\"client-nojs\" version=\"HTML+RDFa 1.0\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>[[Category:Publications]]</title>\\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\\\s)client-nojs(\\\\s|$)/, \"$1client-js$2\" );</script>\\n<script>window.RLQ = window.RLQ || []; window.RLQ.push( function () {\\nmw.config.set({\"wgCanonicalNamespace\":\"Special\",\"wgCanonicalSpecialPageName\":\"Ask\",\"wgNamespaceNumber\":-1,\"wgPageName\":\"Special:Ask/-5B-5BCategory:Publications-5D-5D/-3FHas-20author=Author(s)/-3FYear/-3FPublished-20in/-3FAbstract/-3FHas-20topic=Topic(s)/-3FHas-20domain=Domain(s)/_format=-20csv/limit=-20100/offset=0\",\"wgTitle\":\"Ask/-5B-5BCategory:Publications-5D-5D/-3FHas-20author=Author(s)/-3FYear/-3FPublished-20in/-3FAbstract/-3FHas-20topic=Topic(s)/-3FHas-20domain=Domain(s)/ format=-20csv/limit=-20100/offset=0\",\"wgCurRevisionId\":0,\"wgRevisionId\":0,\"wgArticleId\":0,\"wgIsArticle\":!1,\"wgIsRedirect\":!1,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[],\"wgBreakFrames\":!1,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"mdy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\\n\"wgMonthNamesShort\":[\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],\"wgRelevantPageName\":\"Special:Ask/-5B-5BCategory:Publications-5D-5D/-3FHas-20author=Author(s)/-3FYear/-3FPublished-20in/-3FAbstract/-3FHas-20topic=Topic(s)/-3FHas-20domain=Domain(s)/_format=-20csv/limit=-20100/offset=0\",\"wgRelevantArticleId\":0,\"wgIsProbablyEditable\":!1,\"wgCargoMapClusteringMinimum\":80,\"wgCargoMonthNames\":[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgCargoMonthNamesShort\":[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],\"wgCarg'\n"
     ]
    }
   ],
   "source": [
    "webpage = 'http://wikilit.referata.com/wiki/Special:Ask/-5B-5BCategory:Publications-5D-5D/-3FHas-20author%3DAuthor(s)/-3FYear/-3FPublished-20in/-3FAbstract/-3FHas-20topic%3DTopic(s)/-3FHas-20domain%3DDomain(s)/_format%3D-20csv/limit%3D-20100/offset%3D0'\n",
    "webcontent = urlopen(webpage).read()\n",
    "\n",
    "print(webcontent[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.1) Pseudo code\n",
    "1) First look at the html version of the WikiLit page  \n",
    "    * The table content is under the table class \"sortable wikitable smwtable\". Under this table, we have table heading th, table body tbody, table rows trs with classes row-odd and row-even  \n",
    "    * Under each 'tr' class, we have table division td clases as follows:  \n",
    "        - URL of the Title\n",
    "        - Author(s)\t\n",
    "        - Year\t\n",
    "        - Published in\t\n",
    "        - Abstract\t\n",
    "        - Topic(s)\t\n",
    "        - Domain(s)\n",
    "2) Read the html via BeautifulSoup  \n",
    "3) Extract all info under the table class \"sortable wikitable smwtable\". This will be one single list.  \n",
    "4) Now, read this list and extract info corresponding to the different td classed and export to a csv.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resp = requests.get(webpage)\n",
    "soup = BeautifulSoup(resp.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.2) HTML Structure\n",
    "<img src=\"html_Wikilit.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "print(type(soup))\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.3) Selecting all data for the tag with class =  sortable wikitable smwtable& creating wikitable\n",
    "Wikitable is part of the result and has only the tags under table. The other tags are\n",
    "    - thead - table header\n",
    "    - tr - table row\n",
    "    - td - cell having the classes Author(s), Year, Published in, Abstract, Topic(s), Domain(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "table_classes = {\"class\": [\"sortable wikitable smwtable\"]}\n",
    "wikitable = soup.findAll(\"table\", table_classes)\n",
    "#wikitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wikitable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xa0',\n",
       " 'Author(s)',\n",
       " 'Year',\n",
       " 'Published in',\n",
       " 'Abstract',\n",
       " 'Topic(s)',\n",
       " 'Domain(s)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_headers = [th.getText() for th in soup.findAll('th')]\n",
    "column_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2) Text Data Cleaning\n",
    "    - Read the contents of the wikitable\n",
    "    - get all the rows with the tag tr\n",
    "    - within each row class tr, get the cells corresponding to tags td and th. Note that th class has the table header and td has all the non-header data\n",
    "    - within each cell, get just the text data\n",
    "    - clean the text data stripping unwanted spaces\n",
    "    - Write this text data(list) to a csv file.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_text(cell):\n",
    "    \"\"\" This function reads the cell from wikitable, extracts the text data\n",
    "    cleans the text and returns the list of text that was extracted from each cell td class\"\"\"\n",
    "    text_list = []\n",
    "    for data in cell:\n",
    "        text = data.findAll(text=True)\n",
    "        clean_text = (\n",
    "            ''.join(text) \n",
    "            .strip()\n",
    "        )\n",
    "        text_list += [clean_text]\n",
    "    return text_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Create the code/logic and write to the csv file\n",
    "\n",
    "with open('wikilit_fin.csv', 'w', newline= '', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quoting=csv.QUOTE_ALL)\n",
    "    # Each cell consists of <th> or <td> tag\n",
    "    for index, table in enumerate(wikitable):\n",
    "\n",
    "        for row in table.findAll('tr'):\n",
    "            cell = row.findAll(['th', 'td'])\n",
    "            if cell:\n",
    "                wiki_text = process_text(cell)\n",
    "                csvwriter.writerow(wiki_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Published in</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Topic(s)</th>\n",
       "      <th>Domain(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Wikipedia, the free encyclopedia' as a role m...</td>\n",
       "      <td>Gordon Müller-SeitzGuido Reger</td>\n",
       "      <td>2010</td>\n",
       "      <td>International Journal of Technology Management</td>\n",
       "      <td>Accounts of open source software (OSS) develop...</td>\n",
       "      <td>Contributor motivationPolicies and governanceS...</td>\n",
       "      <td>Information systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A 'resource review' of Wikipedia</td>\n",
       "      <td>Cormac Lawler</td>\n",
       "      <td>2006</td>\n",
       "      <td>Counselling &amp; Psychotherapy Research</td>\n",
       "      <td>The article offers information on Wikipedia, a...</td>\n",
       "      <td>Miscellaneous topics</td>\n",
       "      <td>Information systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Persian web page classifier applying a combi...</td>\n",
       "      <td>Mojgan FarhoodiAlireza YariMaryam Mahmoudi</td>\n",
       "      <td>2009</td>\n",
       "      <td>International Journal of Information Studies</td>\n",
       "      <td>There are many automatic classification method...</td>\n",
       "      <td>Text classification</td>\n",
       "      <td>Computer science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Wikipedia literature review</td>\n",
       "      <td>Owen S. Martin</td>\n",
       "      <td>2010</td>\n",
       "      <td>ArXiv</td>\n",
       "      <td>This paper was originally designed as a litera...</td>\n",
       "      <td>Literature review</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Wikipedia matching approach to contextual ad...</td>\n",
       "      <td>Alexander N. PakChin-Wan Chung</td>\n",
       "      <td>2010</td>\n",
       "      <td>World Wide Web</td>\n",
       "      <td>Contextual advertising is an important part of...</td>\n",
       "      <td>Other information retrieval topics</td>\n",
       "      <td>Computer science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0  'Wikipedia, the free encyclopedia' as a role m...   \n",
       "1                   A 'resource review' of Wikipedia   \n",
       "2  A Persian web page classifier applying a combi...   \n",
       "3                      A Wikipedia literature review   \n",
       "4  A Wikipedia matching approach to contextual ad...   \n",
       "\n",
       "                                    Author(s)  Year  \\\n",
       "0              Gordon Müller-SeitzGuido Reger  2010   \n",
       "1                               Cormac Lawler  2006   \n",
       "2  Mojgan FarhoodiAlireza YariMaryam Mahmoudi  2009   \n",
       "3                              Owen S. Martin  2010   \n",
       "4              Alexander N. PakChin-Wan Chung  2010   \n",
       "\n",
       "                                     Published in  \\\n",
       "0  International Journal of Technology Management   \n",
       "1            Counselling & Psychotherapy Research   \n",
       "2    International Journal of Information Studies   \n",
       "3                                           ArXiv   \n",
       "4                                  World Wide Web   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Accounts of open source software (OSS) develop...   \n",
       "1  The article offers information on Wikipedia, a...   \n",
       "2  There are many automatic classification method...   \n",
       "3  This paper was originally designed as a litera...   \n",
       "4  Contextual advertising is an important part of...   \n",
       "\n",
       "                                            Topic(s)            Domain(s)  \n",
       "0  Contributor motivationPolicies and governanceS...  Information systems  \n",
       "1                               Miscellaneous topics  Information systems  \n",
       "2                                Text classification     Computer science  \n",
       "3                                  Literature review          Mathematics  \n",
       "4                 Other information retrieval topics     Computer science  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a new dataframe from the csv file having wikilit information\n",
    "\n",
    "wiki_df = pd.read_csv('wikilit_fin.csv', encoding='utf-8')\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3) Count the occurrences of all words in the documents.\n",
    "\n",
    "I have 2 scenarios to count the occurrences of all words in the documents:  \n",
    "    * Create a wikilitcorpus with the values from all documents irrespective of fields. Avoid the common words by using stop words and create a bag of words matrix. Count the occurrences by not including the stopwords as well  \n",
    "    * Create a corpus with just the abstract information from the dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.1 Creating wikilit corpus with all words from the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikilitcorpus = wiki_df.values.tolist()\n",
    "## Note that this is a list of lists and hence I need another logic to create a single list from this corpus\n",
    "len(wikilitcorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nw = []\n",
    "for i in range(len(wikilitcorpus)):\n",
    "    nw += wikilitcorpus[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using newwiki in countvectorizer results in error as it has non-string\n",
    "# Converting a list to a string using map\n",
    "newwiki = [''.join(map(str, nw))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1.1 Without using stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wvec = CountVectorizer()\n",
    "wikilit_cnt = wvec.fit_transform(newwiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3677)\n"
     ]
    }
   ],
   "source": [
    "# Summarize\n",
    "print(wikilit_cnt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words matrix\n",
    "print(wikilit_cnt.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(wvec.vocabulary_) ## This lists all the words and the corresponding indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absence', 'abstract', 'abstractions', 'abstracts', 'academic', 'academics', 'accelerating', 'acceleration', 'acceptance', 'access', 'accessible', 'accommodation', 'according', 'account', 'accretion', 'accumulated', 'accuracy', 'accurate', 'accurately', 'achieve', 'achieved', 'achieves', 'achieving', 'acknowledged', 'acm', 'acquaintances', 'acquisition', 'across', 'act', 'acting', 'action', 'actions', 'activate', 'active', 'activities', 'activity', 'actual', 'actually', 'acute', 'adapt', 'adaptable', 'adaptation', 'adapted', 'adaptive', 'adaptively', 'add', 'added', 'addictive', 'adding', 'addition', 'additional', 'address', 'addressed', 'adhocracies', 'adhocracy', 'adjusting', 'adlerkrishnendu', 'adlerluca', 'administrative', 'admission', 'adolescent', 'adopt', 'adopted', 'adopting', 'ads', 'adult', 'advance', 'advanced', 'advances', 'advantage', 'advantages', 'advent', 'adversary', 'advertisers', 'advertising', 'advertisingalexander', 'aesthetic', 'affect', 'affected', 'affecting', 'affection', 'affective', 'afford', 'affordances', 'afforded', 'after', 'against', 'age', 'agencies', 'aggregate', 'aggregated', 'aggregation', 'aghai2010proceedings', 'aghaisimon', 'ago', 'agreed', 'aim', 'aims', 'akin', 'alfaro2007www', 'alfaroian', 'alfonsecapablo', 'algorithm', 'algorithms', 'alhossainili', 'alison', 'all', 'allegedly', 'allow', 'allowed', 'allows', 'almost', 'alone', 'along', 'also', 'altered', 'alternative', 'alternatively', 'although', 'altruism', 'ambiguities', 'ambiguity', 'american', 'amid', 'among', 'amorphous', 'amount', 'amounts', 'an', 'analogous', 'analogy', 'analysed', 'analyses', 'analysing', 'analysis', 'analysisbenjamin', 'analysisevgeniy', 'analysistaha', 'analysistakashi', 'analytes', 'analyze', 'analyzed', 'analyzes', 'analyzing', 'anarchic', 'anarchy', 'and', 'andreas', 'anecdotal', 'anisms', 'annotate', 'annotated', 'annotations', 'annual', 'anonymous', 'anonymously', 'another', 'answer', 'answered', 'answering', 'answers', 'antecedents', 'anti', 'any', 'anyone', 'anytime', 'apart', 'apparent', 'appealing', 'appear', 'appeared', 'appearing', 'appears', 'applicable', 'application', 'applications', 'applicationwikipedia', 'applied', 'apply', 'applying', 'appraise', 'appreciation', 'approach', 'approaches', 'appropriate', 'appropriation', 'approved', 'approximate', 'approximates', 'aragónandreas', 'arazyeleni', 'arazyoded', 'arazyraymond', 'archetypal', 'architecture', 'architectures', 'are', 'area', 'areas', 'arguable']\n"
     ]
    }
   ],
   "source": [
    "print(wvec.get_feature_names()[100:300])## This lists the list of words aka bag of words in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0004</th>\n",
       "      <th>04this</th>\n",
       "      <th>05</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>0robert</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealots</th>\n",
       "      <th>zengmaher</th>\n",
       "      <th>zhangweining</th>\n",
       "      <th>zhourong</th>\n",
       "      <th>zwol2009wsdm</th>\n",
       "      <th>årup</th>\n",
       "      <th>œplainâ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 3677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0001  0004  04this  05  07  08  09  0robert  10   ...     york  you  \\\n",
       "0    3     2     1       1   4   6   2   3        1   5   ...        2    5   \n",
       "\n",
       "   zeal  zealots  zengmaher  zhangweining  zhourong  zwol2009wsdm  årup  \\\n",
       "0     1        1          1             1         1             1     1   \n",
       "\n",
       "   œplainâ  \n",
       "0        1  \n",
       "\n",
       "[1 rows x 3677 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df = pd.DataFrame(wikilit_cnt.toarray(), columns=wvec.get_feature_names())\n",
    "freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocab</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>the</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>of</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>and</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>to</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>in</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vocab  Frequency\n",
       "3282   the        938\n",
       "2278    of        812\n",
       "246    and        558\n",
       "3325    to        439\n",
       "1664    in        342"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdf = freq_df.sum(axis=0)\n",
    "pd.DataFrame({'Vocab': sumdf.index, 'Frequency': sumdf.values}).sort_values(by='Frequency', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### We can see that there are many common occuring words above. We need to filter them out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1.2 Filter out common words by using stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wvecs = CountVectorizer(stop_words='english')\n",
    "wikilit_stop_cnt = wvecs.fit_transform(newwiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3468)\n"
     ]
    }
   ],
   "source": [
    "print(wikilit_stop_cnt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Bag of words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(wikilit_stop_cnt.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(wvecs.vocabulary_) ## This lists all the words and the corresponding indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstractions', 'abstracts', 'academic', 'academics', 'accelerating', 'acceleration', 'acceptance', 'access', 'accessible', 'accommodation', 'according', 'account', 'accretion', 'accumulated', 'accuracy', 'accurate', 'accurately', 'achieve', 'achieved', 'achieves', 'achieving', 'acknowledged', 'acm', 'acquaintances', 'acquisition', 'act', 'acting', 'action', 'actions', 'activate', 'active', 'activities', 'activity', 'actual', 'actually', 'acute', 'adapt', 'adaptable', 'adaptation', 'adapted', 'adaptive', 'adaptively', 'add', 'added', 'addictive', 'adding', 'addition', 'additional', 'address', 'addressed', 'adhocracies', 'adhocracy', 'adjusting', 'adlerkrishnendu', 'adlerluca', 'administrative', 'admission', 'adolescent', 'adopt', 'adopted', 'adopting', 'ads', 'adult', 'advance', 'advanced', 'advances', 'advantage', 'advantages', 'advent', 'adversary', 'advertisers', 'advertising', 'advertisingalexander', 'aesthetic', 'affect', 'affected', 'affecting', 'affection', 'affective', 'afford', 'affordances', 'afforded', 'age', 'agencies', 'aggregate', 'aggregated', 'aggregation', 'aghai2010proceedings', 'aghaisimon', 'ago', 'agreed', 'aim', 'aims', 'akin', 'alfaro2007www', 'alfaroian', 'alfonsecapablo', 'algorithm', 'algorithms', 'alhossainili', 'alison', 'allegedly', 'allow', 'allowed', 'allows', 'altered', 'alternative', 'alternatively', 'altruism', 'ambiguities', 'ambiguity', 'american', 'amid', 'amorphous', 'amounts', 'analogous', 'analogy', 'analysed', 'analyses', 'analysing', 'analysis', 'analysisbenjamin', 'analysisevgeniy', 'analysistaha', 'analysistakashi', 'analytes', 'analyze', 'analyzed', 'analyzes', 'analyzing', 'anarchic', 'anarchy', 'andreas', 'anecdotal', 'anisms', 'annotate', 'annotated', 'annotations', 'annual', 'anonymous', 'anonymously', 'answer', 'answered', 'answering', 'answers', 'antecedents', 'anti', 'anytime', 'apart', 'apparent', 'appealing', 'appear', 'appeared', 'appearing', 'appears', 'applicable', 'application', 'applications', 'applicationwikipedia', 'applied', 'apply', 'applying', 'appraise', 'appreciation', 'approach', 'approaches', 'appropriate', 'appropriation', 'approved', 'approximate', 'approximates', 'aragónandreas', 'arazyeleni', 'arazyoded', 'arazyraymond', 'archetypal', 'architecture', 'architectures', 'area', 'areas', 'arguable', 'argue', 'argues', 'argument', 'arguments', 'arise', 'arising', 'aristotle', 'arrangements', 'arrangementshenk', 'array', 'art', 'article', 'articles', 'articlescomputational', 'articlesinformation', 'articleslucy', 'articlesother', 'articlesquality', 'articlesreadability']\n"
     ]
    }
   ],
   "source": [
    "print(wvecs.get_feature_names()[100:300])## This lists the list of words aka bag of words in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0004</th>\n",
       "      <th>04this</th>\n",
       "      <th>05</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>0robert</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>yields</th>\n",
       "      <th>york</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealots</th>\n",
       "      <th>zengmaher</th>\n",
       "      <th>zhangweining</th>\n",
       "      <th>zhourong</th>\n",
       "      <th>zwol2009wsdm</th>\n",
       "      <th>årup</th>\n",
       "      <th>œplainâ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 3468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0001  0004  04this  05  07  08  09  0robert  10   ...     yields  \\\n",
       "0    3     2     1       1   4   6   2   3        1   5   ...          1   \n",
       "\n",
       "   york  zeal  zealots  zengmaher  zhangweining  zhourong  zwol2009wsdm  årup  \\\n",
       "0     2     1        1          1             1         1             1     1   \n",
       "\n",
       "   œplainâ  \n",
       "0        1  \n",
       "\n",
       "[1 rows x 3468 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df = pd.DataFrame(wikilit_stop_cnt.toarray(), columns=wvecs.get_feature_names())\n",
    "freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocab</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>information</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>based</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>web</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vocab  Frequency\n",
       "3371    wikipedia        261\n",
       "1773    knowledge         95\n",
       "1615  information         82\n",
       "398         based         82\n",
       "3347          web         72"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdf = freq_df.sum(axis=0)\n",
    "pd.DataFrame({'Vocab': sumdf.index, 'Frequency': sumdf.values}).sort_values(by='Frequency', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.2 Creating wikilit corpus with all words from only the abstract and filtering common words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "wikilit_abs_cnt = cvec.fit_transform(wiki_df['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words matrix\n",
    "wikilit_abs_cnt.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2748)\n"
     ]
    }
   ],
   "source": [
    "# Summarize\n",
    "print(wikilit_abs_cnt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(cvec.vocabulary_) ## This lists all the words and the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['achieves', 'achieving', 'acknowledged', 'acquaintances', 'acquisition', 'act', 'acting', 'action', 'actions', 'activate', 'active', 'activities', 'activity', 'actual', 'actually', 'acute', 'adapt', 'adaptable', 'adaptation', 'adapted', 'adaptive', 'adaptively', 'add', 'added', 'addictive', 'adding', 'addition', 'additional', 'address', 'addressed', 'adhocracies', 'adhocracy', 'adjusting', 'administrative', 'admission', 'adopt', 'adopted', 'adopting', 'ads', 'advance', 'advanced', 'advances', 'advantage', 'advantages', 'advent', 'adversary', 'advertisers', 'advertising', 'aesthetic', 'affect', 'affected', 'affecting', 'affection', 'affective', 'afford', 'affordances', 'afforded', 'age', 'agencies', 'aggregate', 'aggregated', 'aggregation', 'ago', 'agreed', 'aim', 'aims', 'akin', 'algorithm', 'algorithms', 'allegedly', 'allow', 'allowed', 'allows', 'altered', 'alternative', 'alternatively', 'altruism', 'ambiguities', 'ambiguity', 'american', 'amid', 'amorphous', 'amounts', 'analogous', 'analogy', 'analysed', 'analyses', 'analysing', 'analysis', 'analytes', 'analyze', 'analyzed', 'analyzes', 'analyzing', 'anarchic', 'anarchy', 'anecdotal', 'anisms', 'annotate', 'annotated', 'annotations', 'anonymous', 'anonymously', 'answer', 'answered', 'answering', 'answers', 'anti', 'anytime', 'apart', 'apparent', 'appealing', 'appear', 'appeared', 'appearing', 'appears', 'applicable', 'application', 'applications', 'applied', 'apply', 'appraise', 'appreciation', 'approach', 'approaches', 'appropriate', 'appropriation', 'approved', 'approximate', 'approximates', 'archetypal', 'architecture', 'architectures', 'area', 'areas', 'arguable', 'argue', 'argues', 'argument', 'arguments', 'arise', 'arising', 'aristotle', 'arrangements', 'array', 'art', 'article', 'articles', 'articulation', 'articulations', 'artificial', 'artists', 'ascertain', 'asian', 'ask', 'asking', 'aspects', 'assertion', 'assess', 'assessed', 'assessing', 'assessment', 'assessments', 'assign', 'assigned', 'assimilation', 'assist', 'assistance', 'associated', 'association', 'associations', 'assumed', 'assumes', 'assumption', 'astonishingly', 'athletes', 'atom', 'atomic', 'attach', 'attack', 'attempt', 'attention', 'attenuating', 'attitude', 'attitudes', 'attracted', 'attracting', 'attribute', 'attributes', 'attribution', 'attuned', 'audience', 'augment', 'augmenting', 'australia', 'author', 'authored', 'authoring', 'authoritative', 'authoritativeness']\n"
     ]
    }
   ],
   "source": [
    "print(cvec.get_feature_names()[100:300]) ## This lists the list of words aka bag of words in alphabetical order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0004</th>\n",
       "      <th>10</th>\n",
       "      <th>102</th>\n",
       "      <th>108</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>115</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>yankees</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>yields</th>\n",
       "      <th>york</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealots</th>\n",
       "      <th>œplainâ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2748 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0001  0004  10  102  108  11  110  115  12   ...     yahoo  yankees  \\\n",
       "0    0     0     0   0    0    0   0    0    0   0   ...         0        0   \n",
       "1    0     0     0   0    0    0   0    0    0   0   ...         0        0   \n",
       "2    0     0     0   0    0    0   0    0    0   0   ...         0        0   \n",
       "3    0     0     0   0    0    0   0    0    0   0   ...         0        0   \n",
       "4    0     0     0   1    0    0   0    0    0   0   ...         0        0   \n",
       "\n",
       "   year  years  yield  yields  york  zeal  zealots  œplainâ  \n",
       "0     0      0      0       0     0     0        0        0  \n",
       "1     0      0      0       0     0     0        0        0  \n",
       "2     0      0      0       0     0     0        0        0  \n",
       "3     0      0      0       0     0     0        0        0  \n",
       "4     0      0      0       0     0     0        0        0  \n",
       "\n",
       "[5 rows x 2748 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df = pd.DataFrame(wikilit_abs_cnt.toarray(), columns=cvec.get_feature_names())\n",
    "freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocab</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>based</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>article</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>web</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Vocab  Frequency\n",
       "2704  wikipedia        237\n",
       "1494  knowledge         74\n",
       "331       based         70\n",
       "246     article         62\n",
       "2693        web         61"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdf = freq_df.sum(axis=0)\n",
    "pd.DataFrame({'Vocab': sumdf.index, 'Frequency': sumdf.values}).sort_values(by='Frequency', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## From occurences to frequencies\n",
    "from scikitlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
